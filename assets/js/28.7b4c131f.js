(window.webpackJsonp=window.webpackJsonp||[]).push([[28],{423:function(t,e,a){"use strict";a.r(e);var s=a(42),n=Object(s.a)({},(function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"graph-algorithms"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#graph-algorithms"}},[t._v("#")]),t._v(" Graph Algorithms")]),t._v(" "),a("p"),a("div",{staticClass:"table-of-contents"},[a("ul",[a("li",[a("a",{attrs:{href:"#topological-sort"}},[t._v("Topological Sort")])]),a("li",[a("a",{attrs:{href:"#dfs-bfs-iddfs"}},[t._v("DFS, BFS, IDDFS")])]),a("li",[a("a",{attrs:{href:"#uninformed-shortest-path-dijkstra-and-floyd-warshall"}},[t._v("Uninformed Shortest Path: Dijkstra and Floyd-Warshall")])]),a("li",[a("a",{attrs:{href:"#informed-search-a"}},[t._v("Informed Search: A*")])]),a("li",[a("a",{attrs:{href:"#ida"}},[t._v("IDA*")])]),a("li",[a("a",{attrs:{href:"#bidirectional-search"}},[t._v("Bidirectional Search")])]),a("li",[a("a",{attrs:{href:"#minimax-alpha-beta-pruning"}},[t._v("Minimax, Alpha-Beta Pruning")])]),a("li",[a("a",{attrs:{href:"#minimum-spanning-tree-prim-s-algorithm"}},[t._v("Minimum Spanning Tree: Prim's Algorithm")])]),a("li",[a("a",{attrs:{href:"#more-graph-problems"}},[t._v("More Graph Problems")])])])]),a("p"),t._v(" "),a("p",[t._v("[TOC]")]),t._v(" "),a("hr"),t._v(" "),a("h2",{attrs:{id:"topological-sort"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#topological-sort"}},[t._v("#")]),t._v(" Topological Sort")]),t._v(" "),a("p",[t._v("Boring. Count the number of in edges and store in a hash. Each round, pick a vertex with no in edges. That's the next vertex. Decrement the vertices which have an in edge here. "),a("code",[t._v("O(|V| + |E|)")]),t._v(".")]),t._v(" "),a("h2",{attrs:{id:"dfs-bfs-iddfs"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#dfs-bfs-iddfs"}},[t._v("#")]),t._v(" DFS, BFS, IDDFS")]),t._v(" "),a("p",[t._v("DFS can be implemented with a stack, BFS with a queue.")]),t._v(" "),a("p",[t._v("BFS is optimal, and will eventually find a solution if it exists ("),a("em",[t._v("complete")]),t._v("). DFS is not necessarily optimal, and in an infinite graph can go down a wrong path forever; it also has problems with loops.")]),t._v(" "),a("p",[t._v("DFS is much better at memory usage: it runs proportional to depth of the tree, while BFS uses "),a("code",[t._v("O(b^d')")]),t._v(" memory, where "),a("code",[t._v("d'")]),t._v(" is depth of the best solution.")]),t._v(" "),a("p",[t._v("You can fix the BFS space problem by running iterative-deepening DFS, which just performs a depth-limited DFS search for increasing depths. This is a complete and optimal solution. Also, since most vertices are at the last level, this still runs in "),a("code",[t._v("O(b^d')")]),t._v(" time!")]),t._v(" "),a("p",[a("strong",[t._v("Backtracking")])]),t._v(" "),a("ul",[a("li",[t._v("You can give up on a branch if you realize it can't possibly lead to success.")])]),t._v(" "),a("h2",{attrs:{id:"uninformed-shortest-path-dijkstra-and-floyd-warshall"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#uninformed-shortest-path-dijkstra-and-floyd-warshall"}},[t._v("#")]),t._v(" Uninformed Shortest Path: Dijkstra and Floyd-Warshall")]),t._v(" "),a("p",[t._v("Dijkstra's algorithm just grows paths by adding path extensions one at a time. There are three approaches:")]),t._v(" "),a("ul",[a("li",[t._v("Keep track of best paths to all "),a("code",[t._v("V")]),t._v(" vertices: "),a("code",[t._v("O(E + V**2)")]),t._v(".")]),t._v(" "),a("li",[t._v("Use a binary heap: "),a("code",[t._v("O((E + V) * log(V))")]),t._v(".\n"),a("ul",[a("li",[t._v("Worse for dense graphs.")])])]),t._v(" "),a("li",[t._v("Use a Fibonacci heap: "),a("code",[t._v("O(E + V * log(V))")]),t._v(".\n"),a("ul",[a("li",[t._v("Updates are cheap!")]),t._v(" "),a("li",[t._v("Best of both worlds, except probably slower than either because Fib heaps are slow and complicated.")])])])]),t._v(" "),a("p",[t._v("If you want to find all-pairs shortest paths, you can run Dijkstra's "),a("code",[t._v("V")]),t._v(" times. However, if you have a dense graph, you might also use the Floyd-Warshal algorithm:")]),t._v(" "),a("ul",[a("li",[t._v("Dynamic programming algorithm that loosens a constraint of only traveling through a subset of vertices.")]),t._v(" "),a("li",[a("code",[t._v("V")]),t._v(" runs: each time, you select a vertex, updating "),a("code",[t._v("V**2")]),t._v(" paths.")])]),t._v(" "),a("p",[t._v("In a dense graph, Floyd-Warshall has better practical performance than Dijkstra. But for a sparse graph the repeated Fibonacci Dijkstra is better. "),a("em",[t._v("Except that Floyd-Warshall can deal with negative edges")]),t._v(".")]),t._v(" "),a("p",[t._v("Since I don't give a shit, I don't talk about "),a("em",[t._v("Bellman-Ford")]),t._v(" or "),a("em",[t._v("Johnson's Algorithm")]),t._v(", which can handle "),a("strong",[t._v("negative cycles")]),t._v(". Fuck that.")]),t._v(" "),a("p",[t._v("In the case of trees with a branching factor of "),a("code",[t._v("b")]),t._v(", then the longest path you must consider is of length "),a("code",[t._v("C/eps")]),t._v(", where "),a("code",[t._v("eps")]),t._v(" is a lower bound on the cost of an edge, while "),a("code",[t._v("C")]),t._v(" is the cost of the best path. Therefore, we can take "),a("code",[t._v("V=C/eps")]),t._v(".")]),t._v(" "),a("h2",{attrs:{id:"informed-search-a"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#informed-search-a"}},[t._v("#")]),t._v(" Informed Search: A*")]),t._v(" "),a("p",[a("strong",[t._v("A*")]),t._v(" is a souped-up Dijkstra's algorithm. It requires an "),a("em",[t._v("admissable heuristic")]),t._v(": one which is optimistic about the distance from a vertex to the target. In the priority queue, we take into acount not only the path's cost, but the expected further distance to travel to a goal node.")]),t._v(" "),a("p",[t._v("Generally speaking, this is the same as Dijkstra, which just has a heuristic of "),a("code",[t._v("0")]),t._v(". The algorithm is complete and optimal. It will give up on bad paths eventually as it slowly realizes the heuristic was optimistic.")]),t._v(" "),a("p",[a("strong",[t._v("Correction:")]),t._v(" You need a "),a("em",[t._v("consistent")]),t._v(" (AKA monotone) heuristic. This one has the property that:")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[t._v("h(n) <= c(n, n') + h(n')\n")])])]),a("p",[t._v("for all successors "),a("code",[t._v("n'")]),t._v(" of "),a("code",[t._v("n")]),t._v(". The reason this is important is that when you expand a node, you need to know that you were considering not just what you think is the probable best path to the target, but in fact "),a("em",[t._v("the best path to that interior node")]),t._v(".")]),t._v(" "),a("p",[a("strong",[t._v("Result")]),t._v(": When the search is in a tree AND the error of the heuristic function is logarithmic, then the time complexity is polynomial! "),a("strong",[t._v("TODO2: Prove me!")])]),t._v(" "),a("p",[t._v("Note that A* is optimal for any heuristic searching out from the root, because it needs to consider exactly those paths it considers, lest it miss a shortcut to the target. Of course, there are other possible algorithms that don't just start from the root...")]),t._v(" "),a("p",[t._v("NB: A heuristic that dominates another ("),a("code",[t._v("h_2(n) > h_1(n)")]),t._v(" for all "),a("code",[t._v("n")]),t._v(") will yield better performance, assuming of course it is still acceptable.")]),t._v(" "),a("h2",{attrs:{id:"ida"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#ida"}},[t._v("#")]),t._v(" IDA*")]),t._v(" "),a("p",[t._v("Both Dijkstra and A* both suffer from very large memory requirements. Another approach is to modify IDDFS to use a heuristic. In this case, you set a "),a("code",[t._v("bound")]),t._v(" for total path cost; you then search in a DFS manner, abandoning a path when the heuristic total cost "),a("code",[t._v("g(a) + h(a)")]),t._v(" greater than the bound.")]),t._v(" "),a("p",[t._v("Like IDDFS, this runs in multiple rounds. Start the bound at zero. Abandon paths as above; but also keep track of the cost of the minimum abandoned path. In the next round, use this cost as the new bound to ensure progress.")]),t._v(" "),a("div",{staticClass:"language-ruby extra-class"},[a("pre",{pre:!0,attrs:{class:"language-ruby"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("IDAStarSolver")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token method-definition"}},[a("span",{pre:!0,attrs:{class:"token function"}},[t._v("run")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    bound "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" h"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("root"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    loop "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n      result "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" search"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("root"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bound"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" result"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token symbol"}},[t._v(":found")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" result"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("has_key"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token symbol"}},[t._v(":found")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      bound "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" result "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token symbol"}},[t._v(":abandonment_cost")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token method-definition"}},[a("span",{pre:!0,attrs:{class:"token function"}},[t._v("search")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cost"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bound"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" cost "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" h"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" bound\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Abandon this route!")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" abandonment_cost"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" cost "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" h"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" found"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" node "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" is_goal"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    abandonment_cost "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("nil")]),t._v("\n    node"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out_edges"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("each")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("edge"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n      new_cost "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cost "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cost\n      result "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" search"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_vertex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" new_cost"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bound"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# May have found it!")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" result "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" result"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("has_key"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token symbol"}},[t._v(":found")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# May have given up!")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" abandonment_cost"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("nil")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("||")]),t._v(" result"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token symbol"}},[t._v(":abandonment_cost")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" abandonment_cost\n        abandonment_cost "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" result"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token symbol"}},[t._v(":abandonment_cost")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" abandonment_cost\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),a("p",[t._v("This returns an optimal path, with much reduced memory usage (proportionate) to length path. However, it may have higher computational overhead because of the necessity of revisiting nodes. It also in some sense doesn't use enough memory; it just remembers a ceiling heuristic value.")]),t._v(" "),a("p",[t._v("An alternative is "),a("strong",[t._v("SMA*")]),t._v(", which expands the graph at the leaves in an "),a("code",[t._v("A*")]),t._v(" manner. When it runs out of space, it drops the low cost leaf, writing into its parent that we should return when we've explored all nodes of lower cost. The parent can be added to the \"leaf\" set. In this way, we don't need to keep revisiting early parts of the tree as we do in "),a("code",[t._v("IDA*")]),t._v(".")]),t._v(" "),a("h2",{attrs:{id:"bidirectional-search"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#bidirectional-search"}},[t._v("#")]),t._v(" Bidirectional Search")]),t._v(" "),a("p",[t._v("Start from both ends and work toward the others. When you link up, you have a path. You can use BFS or IDDFS in which case the result will be optimal. You need to keep one of the fringes in memory, so space usage is "),a("code",[t._v("O(b^d)")]),t._v(" if we're talking a tree.")]),t._v(" "),a("p",[t._v('On the other hand, you can use A* targeting the other source. It seems that the result may not be optimal. There is also a concept of "front-to-front" search where a heuristic exists to move toward the '),a("em",[t._v("front")]),t._v(", and not the *back*. This may be optimal. However, this is pretty expensive.")]),t._v(" "),a("h2",{attrs:{id:"minimax-alpha-beta-pruning"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#minimax-alpha-beta-pruning"}},[t._v("#")]),t._v(" Minimax, Alpha-Beta Pruning")]),t._v(" "),a("p",[t._v("Minimax strategy is to make the best move, assuming your opponent makes the worst move for you and you respond with the best. Basically, you try to maximize, then they try to minimize...")]),t._v(" "),a("p",[t._v("You can of course do this to completion with a "),a("code",[t._v("+1")]),t._v(" for winning and a "),a("code",[t._v("-1")]),t._v(" for losing (and maybe a "),a("code",[t._v("0")]),t._v(" for drawing). This of course doesn't work for deep game trees, so we use heuristics to guide the search. For instance, look 12 moves ahead and then apply the heuristic.")]),t._v(" "),a("p",[t._v("Imagine that the minimizing player sees they can force a loss by taking the first branch of the move tree from a given position. Then there is no need to consider the other branches. Alpha-Beta pruning extends this logic. If the maximizing player sees they can force a score of "),a("code",[t._v("x")]),t._v(" on the first branch, then they need to check the other branches. However, as soon as the minimizing player realizes they can force a score less than "),a("code",[t._v("x")]),t._v(", they can abandon this path, because things can only get worse for the maximizer, and thus they will not take this path.")]),t._v(" "),a("p",[t._v("Let alpha be the maximum score that the maximizer knows they can force, where beta is the minimum score that the minimizer knows they can force. As the search plays out, alpha and beta will approach each other until they become equal. To start, alpha may be "),a("code",[t._v("-1")]),t._v(" and "),a("code",[t._v("+1")]),t._v(", since we know that the maximizer can't do worse that lose, and vice-versa.")]),t._v(" "),a("div",{staticClass:"language-ruby extra-class"},[a("pre",{pre:!0,attrs:{class:"language-ruby"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token method-definition"}},[a("span",{pre:!0,attrs:{class:"token function"}},[t._v("search")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" player"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" depth"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" alpha"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" beta"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("node"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" heuristic"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" h"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" depth "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" player "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Try to maximize!")]),t._v("\n    max_path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" max_path_score "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("nil")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("nil")]),t._v("\n    node"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("children"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("each")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("child"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n      path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" path_score "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" search"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n        child"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        depth "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        alpha"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        beta\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("values_at"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token symbol"}},[t._v(":path")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token symbol"}},[t._v(":heuristic")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("next")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("nil")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),t._v("\n\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Is this the best move we've seen so far?")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" max_path_score"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("nil")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("||")]),t._v(" path_score "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" max_path_score\n        max_path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" max_path_score "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" max_path_score\n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# If considering a branch where the opponent can force a result")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# worse than alpha, forget it, since this is the better option.")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" alpha "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" path_score\n        alpha "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" path_score\n\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Beta was previously set to the worst result the opponent")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# could force. But now we see that if the opponent must never")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# allow us to move to node, because then the maximizer could")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# force a better result.")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" abandoned"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" beta "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" alpha\n      "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" max_path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" heuristic"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" max_path_score "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Analogous!")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),t._v("\n")])])]),a("h2",{attrs:{id:"minimum-spanning-tree-prim-s-algorithm"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#minimum-spanning-tree-prim-s-algorithm"}},[t._v("#")]),t._v(" Minimum Spanning Tree: Prim's Algorithm")]),t._v(" "),a("p",[t._v("Just stupid Dijkstra's. Doesn't take into account of existing path, just the cost of the next edge. Same performance characteristics.")]),t._v(" "),a("p",[t._v("Kruskal's Algorithm is apparently more performant in sparse graphs, though has same time bounds. It uses union-find datastructure which seems boring.")]),t._v(" "),a("p",[t._v("BorÅ¯vka's algorithm is apparently very parallelizable. Could actually be interesting. "),a("strong",[t._v("Todo")])]),t._v(" "),a("h2",{attrs:{id:"more-graph-problems"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#more-graph-problems"}},[t._v("#")]),t._v(" More Graph Problems")]),t._v(" "),a("ul",[a("li",[t._v("Johnson's Algorithm allows faster all-pairs shortest path "),a("em",[t._v("on sparse graphs")]),t._v(".")]),t._v(" "),a("li",[t._v("Min cut")]),t._v(" "),a("li",[t._v("Smallest max-edge path")]),t._v(" "),a("li",[t._v("Largest min-edge path")]),t._v(" "),a("li",[t._v("K-shortest paths")]),t._v(" "),a("li",[t._v("Clique detection")]),t._v(" "),a("li",[t._v("Embedding")]),t._v(" "),a("li",[t._v("Strongly Connected components")])])])}),[],!1,null,null,null);e.default=n.exports}}]);